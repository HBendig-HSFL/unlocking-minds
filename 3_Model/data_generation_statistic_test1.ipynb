{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Evaluation\n",
    "## Table of Contents\n",
    "1. [Model Selection](#model-selection)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "3. [Hyperparameter Tuning](#hyperparameter-tuning)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Evaluation Metrics](#evaluation-metrics)\n",
    "6. [Comparative Analysis](#comparative-analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:31:12.884725Z",
     "start_time": "2024-06-13T05:31:08.391501Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.src.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:31:12.894125Z",
     "start_time": "2024-06-13T05:31:12.885597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Beispiel Daten laden\n",
    "data = pd.read_csv('./../Data/preprocessed_df.csv') # Pfad zu Ihren Daten\n",
    "\n",
    "# Daten skalieren\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Dimension der Eingabedaten\n",
    "input_dim = data_scaled.shape[1]\n",
    "\n",
    "print(data_scaled[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.0030929  0.05263158 0.         0.10526316\n",
      "  0.26315789 0.21052632 0.05263158 0.135      0.7440808  0.74566782\n",
      "  0.06140543 0.53601451]\n",
      " [0.         0.33333333 0.00238009 0.47368421 0.26315789 0.21052632\n",
      "  0.52631579 0.10526316 0.21052632 0.35375    0.70649122 0.71014102\n",
      "         nan 0.31792393]\n",
      " [0.         0.66666667 0.00831226 1.         0.05263158 0.73684211\n",
      "  0.84210526 0.89473684 0.15789474 0.72875    0.77876653 0.78222397\n",
      "  0.20582482 0.35502628]\n",
      " [0.         1.         0.00371728 0.57894737 0.10526316 0.42105263\n",
      "  0.52631579 0.15789474 0.21052632 0.395      0.82198233 0.8251407\n",
      "  0.05396077 0.52209791]\n",
      " [0.02173913 0.         0.0042125  0.15789474 0.05263158 0.15789474\n",
      "  0.10526316 0.15789474 0.10526316 0.145      0.23894266 0.23658067\n",
      "  0.0492023  0.26031593]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:34:32.907971Z",
     "start_time": "2024-06-13T05:34:32.899115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Berechnen Sie den Mittelwert und die Standardabweichung f체r jede Eigenschaft der skalierten Daten\n",
    "means = np.mean(data_scaled, axis=0)\n",
    "stds = np.std(data_scaled, axis=0)\n",
    "\n",
    "# Anzahl der zu generierenden Datenpunkte\n",
    "num_additional_points = 1000\n",
    "\n",
    "# Generieren Sie zus채tzliche skalierten Datenpunkte basierend auf den Mittelwerten und Standardabweichungen\n",
    "synthetic_data_scaled = np.random.normal(loc=means, scale=stds, size=(num_additional_points, data_scaled.shape[1]))\n",
    "\n",
    "# Die generierten Daten zur체ckskalieren auf den urspr체nglichen Wertebereich\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data_scaled)\n",
    "\n",
    "# Die generierten Daten mit den Originaldaten kombinieren\n",
    "augmented_data = np.vstack((data, synthetic_data))\n",
    "\n",
    "# Optional: Konvertieren Sie die Daten in ein TensorFlow-Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(augmented_data)\n",
    "\n",
    "print(\"Original Data Shape:\", data.shape)\n",
    "print(\"Synthetic Data Shape:\", synthetic_data.shape)\n",
    "print(\"Augmented Data Shape:\", augmented_data.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (188, 14)\n",
      "Synthetic Data Shape: (1000, 14)\n",
      "Augmented Data Shape: (1188, 14)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T05:34:34.890160Z",
     "start_time": "2024-06-13T05:34:34.883722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "augmented_data = pd.DataFrame(augmented_data, columns=data.columns)\n",
    "\n",
    "print(augmented_data[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant_id  test_id  test_duration  mental  physical  temporal  \\\n",
      "0             1.0      1.0      33.643950    10.0       5.0      15.0   \n",
      "1             1.0      2.0      28.484322    50.0      30.0      25.0   \n",
      "2             1.0      3.0      71.423823   100.0      10.0      75.0   \n",
      "3             1.0      4.0      38.163442    60.0      15.0      45.0   \n",
      "4             2.0      1.0      41.748047    20.0      10.0      20.0   \n",
      "\n",
      "   performance  effort  frustration  mean  mean_pupil_diameter  \\\n",
      "0         25.0    25.0         10.0  15.0            43.855534   \n",
      "1         50.0    15.0         25.0  32.5            42.935538   \n",
      "2         80.0    90.0         20.0  62.5            44.704459   \n",
      "3         50.0    20.0         25.0  35.8            45.762156   \n",
      "4         10.0    20.0         15.0  15.8            31.492393   \n",
      "\n",
      "   median_pupil_diameter  blinkrate  fixationrate  \n",
      "0              43.893976   0.059446      0.295946  \n",
      "1              43.021599        NaN      0.175533  \n",
      "2              44.791630   0.196013      0.196018  \n",
      "3              45.845470   0.052406      0.288263  \n",
      "4              31.393101   0.047906      0.143727  \n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
