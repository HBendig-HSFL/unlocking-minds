{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Table of Contents\n",
    "1. [Dataset Overview](#dataset-overview)\n",
    "2. [Handling Missing Values](#handling-missing-values)\n",
    "3. [Feature Distributions](#feature-distributions)\n",
    "4. [Possible Biases](#possible-biases)\n",
    "5. [Correlations](#correlations)\n",
    "6. [Correlations](#correlations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "The original dataset was in a Matlab format. The data was converted to CSV format for easier handling. The self-developed Matlab-Export--Scripts are in the folder [Matlab-Export-Scripts](./MatlabExport).\n",
    "\n",
    "- The Data are recorded with 240Hz\n",
    "- The NASA TLX Scores are recorded after each task\n",
    "\n",
    "The Description of the original data is as follows:\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to expand</summary>\n",
    "\n",
    "---Title---\n",
    "\n",
    "COLET: A Dataset for Cognitive Workload Estimation based on Eye-tracking\n",
    "\n",
    "---Contributors---\n",
    "\n",
    "Emmanouil Ktistakis,Institute of Computer Science, Foundation for Research and Technology Hellas (FORTH) and the Laboratory of Optics and Vision, School of Medicine, University of Crete, GR-710 03 Heraklion, Greece\n",
    "Vasileios Skaramagkas, Institute of Computer Science, Foundation for Research and Technology Hellas (FORTH), GR-700 13 Heraklion, Crete, Greece, ORCID: 0000-0002-3279-8016\n",
    "Dimitris Manousos, Institute of Computer Science, Foundation for Research and Technology Hellas (FORTH), GR-700 13 Heraklion, Crete, Greece\n",
    "Nikolaos S. Tachos, Department of Biomedical Research, Institute of Molecular Biology and Biotechnology, FORTH, GR-451 15, Ioannina, Greece and the Department of Materials Science and Engineering, Unit of Medical Technology and Intelligent Information Systems, University of Ioannina, GR-451 10, Ioannina, Greece\n",
    "Evanthia Tripoliti, Department of Materials Science and Engineering, Unit of Medical Technology and Intelligent Information Systems, University of Ioannina, GR-451 10, Ioannina, Greece\n",
    "Dimitrios I. Fotiadis, Department of Biomedical Research, Institute of Molecular Biology and Biotechnology, FORTH, GR-451 15, Ioannina, Greece and the Department of Materials Science and Engineering, Unit of Medical Technology and Intelligent Information Systems, University of Ioannina, GR-451 10, Ioannina, Greece\n",
    "Manolis Tsiknakis, Institute of Computer Science, Foundation for Research and Technology Hellas (FORTH) and the Department of Electrical and Computer Engineering, Hellenic Mediterranean University, GR-710 04 Heraklion, Crete, Greece\n",
    "\n",
    "\n",
    "---Corresponding Authors---\n",
    "\n",
    "Vasileios Skaramagkas, vskaramagkas96@gmail.com\n",
    "Emmanouil Ktistakis, mankti@ics.forth.gr\n",
    "\n",
    "\n",
    "---DOI---\n",
    "\n",
    "10.2139/ssrn.4059768 (temporary)\n",
    "\n",
    "---database Description---\n",
    "\n",
    "Database including eye movements from 47 participants as they solved puzzles involving visual search tasks of varying complexity and duration.\n",
    "Participants rated their performance based on NASA RTLX index scale.\n",
    "\n",
    "The uploaded files include:\n",
    "1) \"data.mat\": the database in Matlab cell and struct-type format.\n",
    "2) \"tasks\" folder: A folder containing the 21 tasks shown.\n",
    "3) \"readme.txt\": a text file providing more information on the database structure.\n",
    "\n",
    "\n",
    "Part of the dataset was used in the work accepted for publication in: 10.2139/ssrn.4059768\n",
    "\n",
    "\n",
    "Please refer to the above mentioned article for more information on the data acquisition protocol.\n",
    "\n",
    "\n",
    "---database Structure---\n",
    "\n",
    "\"data.mat\": A matlab workspace file containing 'data' 1x47 cell-vector, which expands to\n",
    "47 structs, each containing information and recordings from a single subject involved in the 4 tasks.\n",
    "\n",
    "Version 1:\n",
    "\n",
    "Each data struct contains the following three fields:\n",
    "\n",
    "a) data{#}.task{i}\n",
    "\n",
    "where i = [1,4] and is the task number (please refer to the respective publication for more info on the tasks)\n",
    "\n",
    "Struct including the following subject information in struct format:\n",
    "\n",
    "task{i}.gaze --> Gaze related metrics recorded from the eye tracker for each of the 4 total tasks (gaze_timestamp, world_index, confidence, norm_pos_x, norm_pos_y, base_data, gaze_point_3d_x, \n",
    "\t\t\t\t\t\t\t\t\tgaze_point_3d_y, gaze_point_3d_z, eye_center0_3d_x, eye_center0_3d_y, eye_center0_3d_z, gaze_normal0_x, gaze_normal0_y, gaze_normal0_z, \n",
    "\t\t\t\t\t\t\t\t\teye_center1_3d_x, eye_center1_3d_y, eye_center1_3d_z, gaze_normal1_x, gaze_normal1_y, gaze_normal1_z)\n",
    "\n",
    "task{i}.pupil --> Pupil related metrics recorded from the eye tracker for each of the 4 total tasks (pupil_timestamp, world_index, eye_id, confidence, norm_pos_x, norm_pos_y, diameter, method,\n",
    " \t\t\t\t\t\t\t\t\tellipse_center_x, ellipse_center_y, ellipse_axis_a, ellipse_axis_b, ellipse_angle, diameter_3d, model_confidence, model_id, sphere_center_x, \n",
    "\t\t\t\t\t\t\t\t\tsphere_center_y, sphere_center_z, sphere_radius, circle_3d_center_x, circle_3d_center_y, circle_3d_center_z, circle_3d_normal_x, circle_3d_normal_y, \n",
    "\t\t\t\t\t\t\t\t\tcircle_3d_normal_z, circle_3d_radius, theta, phi, projected_sphere_center_x,projected_sphere_center_y, projected_sphere_axis_a, projected_sphere_axis_b, \n",
    "\t\t\t\t\t\t\t\t\tprojected_sphere_angle)\n",
    "\n",
    "task{i}.blinks --> Blink related metrics recorded from the eye tracker for each of the 4 total tasks (id, start_timestamp, duration, end_timestamp, start_frame_index, index, end_frame_index, confidence,\n",
    "\t\t\t\t\t\t\t\t        filter_response, base_data)\n",
    "\n",
    "task{i}.annotation --> NASA RTLX scores for each of the 4 total tasks\n",
    "\n",
    "For more info regarding the recordings from Pupil Core visit: https://docs.pupil-labs.com/core/software/pupil-capture/\n",
    "\n",
    "\n",
    "b) data{#}.subject_info\n",
    "\n",
    "Struct including general subject information:\n",
    "\n",
    "1) Visual acuity: measured binocularly in distance of 0.80cm (logMAR)\n",
    "2) Gender ('F': Female, 'M': Male)  \n",
    "3) Age (years) \n",
    "4) Education level (years)\n",
    "\n",
    "\n",
    "c) \"images\" folder: Folder containing the images used in the experiment\n",
    "\n",
    "1 --> bowling_balls\n",
    "2 --> candles\n",
    "3 --> chandelier\n",
    "4 --> classroom\n",
    "5 --> garage\n",
    "6 --> handles\n",
    "7 --> kitchen\n",
    "8 --> light\n",
    "9 --> paintings_1\n",
    "10 --> paintings_2\n",
    "11 --> pc_screens\n",
    "12 --> pillows\n",
    "13 --> poof\n",
    "14 --> pool\n",
    "15 --> seats_1\n",
    "16 --> seats_2\n",
    "17 --> shoes\n",
    "18 --> students\n",
    "19 --> towels\n",
    "20 --> water\n",
    "21 --> windows\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "For more information, please refer to the following article:\n",
    "\n",
    "Ktistakis, E., Skaramagkas, V., Manousos, D., Tachos, N. S., Tripoliti, E., Fotiadis, D. I., & Tsiknakis, M. (2022). Colet: A dataset for cognitive workload estimation based on eye-tracking. Computer Methods and Programs in Biomedicine, 106989. https://doi.org/10.1016/j.cmpb.2022.106989\n",
    "\n",
    "Last Update: 2022/06/07\n",
    " \n",
    "</details>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# New Data Format\n",
    "\n",
    "The new data structure is as follows:\n",
    "- Participants.csv: Contains the participant information with some demographic data and a unique participant ID.\n",
    "- Participant_X\n",
    "    - Test1: 5 Images, no time constraint, no secondary task.\n",
    "        - Participant_X_Annotations_1.csv: Contains the annotations for the test.\n",
    "        - Participant_X_Blinks_1.csv: Contains the blinks data for the test.\n",
    "        - Participant_X_Gaze_1.csv: Contains the gaze data for the test.\n",
    "        - Participant_X_Pupil_1.csv: Contains the pupil data for the test.\n",
    "    - Test2: 5 iamges, with time constraint, no secondary task.\n",
    "    - Test3: 5 images, with time constraint, with secondary task.\n",
    "    - Test4: 5 images, no time constraint, with secondary task."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:00:50.917536Z",
     "start_time": "2024-05-22T14:00:50.913628Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:35:39.170351Z",
     "start_time": "2024-05-22T13:35:39.162788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Variables\n",
    "data_path = '../Data/'\n",
    "\n",
    "# Load data\n",
    "participant_list = pd.read_csv(data_path + 'participants.csv')\n",
    "print(participant_list.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  VisualAcuity_logMAR_ Gender  Age  Education\n",
      "0   1                 -0.04      F   28         18\n",
      "1   2                 -0.10      F   28         18\n",
      "2   3                 -0.08      F   38         16\n",
      "3   4                 -0.07      F   29         18\n",
      "4   5                 -0.15      M   30         18\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:14:33.355223Z",
     "start_time": "2024-05-22T14:14:33.260749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "participant_number = 1\n",
    "test_number = 1\n",
    "\n",
    "path_to_participant = data_path + 'Participant_' + str(participant_number) \n",
    "path_to_test = path_to_participant + '/Test' + str(test_number) + '/'\n",
    "path_to_annotations = path_to_test + 'Participant_' + str(participant_number) + '_Annotations_' + str(test_number) + '.csv'\n",
    "path_to_blinks = path_to_test + 'Participant_' + str(participant_number) + '_Blinks_' + str(test_number) + '.csv'\n",
    "path_to_gaze = path_to_test + 'Participant_' + str(participant_number) + '_Gaze_' + str(test_number) + '.csv'\n",
    "path_to_pupil = path_to_test + 'Participant_' + str(participant_number) + '_Pupil_' + str(test_number) + '.csv'\n",
    "\n",
    "test1_participant1_annotations = pd.read_csv(path_to_annotations)\n",
    "test1_participant1_blinks = pd.read_csv(path_to_blinks)\n",
    "test1_participant1_gaze = pd.read_csv(path_to_gaze)\n",
    "test1_participant1_pupil = pd.read_csv(path_to_pupil)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:38:17.204979Z",
     "start_time": "2024-05-22T13:38:17.198616Z"
    }
   },
   "cell_type": "code",
   "source": "print(test1_participant1_blinks.head())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  start_timestamp  duration  end_timestamp  start_frame_index  index  \\\n",
      "0   1      5437.625617  0.236131    5437.861748                 37     40   \n",
      "1   2      5444.161561  0.180073    5444.341634                231    233   \n",
      "\n",
      "   end_frame_index  confidence  \\\n",
      "0               44    0.703872   \n",
      "1              236    0.553669   \n",
      "\n",
      "                                     filter_response  \\\n",
      "0  0.5068225043614704 0.5512669488059149 0.595711...   \n",
      "1  0.5048782729116744 0.5493227173561188 0.592878...   \n",
      "\n",
      "                                           base_data  \n",
      "0  5437.625617 5437.629564 5437.633621 5437.63786...  \n",
      "1  5444.161561 5444.165642 5444.169793 5444.17554...  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "[Provide a high-level overview of the dataset. This should include the source of the dataset, the number of samples, the number of features, and example showing the structure of the dataset.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Number of samples\n",
    "num_samples = df.shape[0]\n",
    "\n",
    "# Number of features\n",
    "num_features = df.shape[1]\n",
    "\n",
    "# Display these dataset characteristics\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "\n",
    "# Display the first few rows of the dataframe to show the structure\n",
    "print(\"Example data:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "[Identify any missing values in the dataset, and describe your approach to handle them if there are any. If there are no missing values simply indicate that there are none.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Example: Replacing NaN values with the mean value of the column\n",
    "# df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Your code for handling missing values goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions\n",
    "\n",
    "[Plot the distribution of various features and target variables. Comment on the skewness, outliers, or any other observations.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plotting histograms of all numerical features\n",
    "df.hist(figsize=(12, 12))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Biases\n",
    "\n",
    "[Investigate the dataset for any biases that could affect the model’s performance and fairness (e.g., class imbalance, historical biases).]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Checking for class imbalance in a classification problem\n",
    "# sns.countplot(x='target_variable', data=df)\n",
    "\n",
    "# Your code to investigate possible biases goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "[Explore correlations between features and the target variable, as well as among features themselves.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plotting a heatmap to show feature correlations\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
